{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings data\n",
    "ratings_path = './ml-latest-small/ratings.csv'\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "\n",
    "# Display ratings dataframe\n",
    "print(\"Ratings DataFrame:\")\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of users\n",
    "print(\"Number of users: \", len(ratings_df['userId'].unique()))\n",
    "\n",
    "# Show mumber of ratings per user\n",
    "user_rating_counts = ratings_df['userId'].value_counts()\n",
    "\n",
    "# Show quantiles\n",
    "print(\"\\nQuantiles of user ratings:\\n\", user_rating_counts.quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0]))\n",
    "\n",
    "rating_cap = 98\n",
    "\n",
    "# Show number of users with less than rating_cap ratings, which is the 50th percentile\n",
    "print(f'\\nNumber of users with less than {rating_cap} ratings: {len(user_rating_counts[user_rating_counts < rating_cap])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the ratings dataframe with only users with 31 or more ratings\n",
    "ratings_df = ratings_df[ratings_df['userId'].isin(user_rating_counts[user_rating_counts >= rating_cap].index)]\n",
    "\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies data\n",
    "movies_path = './ml-latest-small/movies.csv'\n",
    "movies_df = pd.read_csv(movies_path)\n",
    "\n",
    "# Display movies dataframe\n",
    "print(\"Movies DataFrame:\")\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove movies with no ratings from movies_df\n",
    "movies_df = movies_df[movies_df.movieId.isin(ratings_df.movieId)].reset_index(drop=True)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with movieId, numRatings, meanRating\n",
    "movieProperties_df = ratings_df.groupby('movieId').agg({'rating': ['size', 'mean']})\n",
    "movieProperties_df.columns = ['numRatings', 'meanRating']\n",
    "\n",
    "# Merge with movies_df to add movie title and genres\n",
    "movieProperties_df = movieProperties_df.merge(movies_df, on='movieId')\n",
    "movieProperties_df = movieProperties_df[['movieId', 'title', 'numRatings', 'meanRating', 'genres']]\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(\"Movie Properties DataFrame:\")\n",
    "movieProperties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph of mean ratings vs number of ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(movieProperties_df['numRatings'], movieProperties_df['meanRating'], alpha=0.5)\n",
    "plt.title('Mean rating vs. Number of ratings')\n",
    "plt.xlabel('Number of ratings')\n",
    "plt.ylabel('Mean rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider implementing a strategy to filter out movies with a low number of ratings, as they may not be representative of the true expected rating. Currently, I am only using a threshold for the number of ratings, but a more sophisticated strategy could be implemented.\n",
    "# Such a strategy could involve using a weighted mean rating, such as beysian average, or adusting the cost function to account for the number of ratings.\n",
    "\n",
    "# Apply a beysian average to the ratings\n",
    "# Parameters\n",
    "itemRatings = movieProperties_df['numRatings'] # V is the number of ratings for the movie\n",
    "itemRatingsAverage = movieProperties_df['meanRating'] # R is the average rating for the movie\n",
    "M = ratings_df['rating'].mean() # M is the mean rating across all movies\n",
    "C = itemRatings.quantile(0.65) # C is the threshhold of the lower 25% of the number of ratings, in this case 65% of the number of ratings, due to scarcity of ratings\n",
    "print(itemRatings.quantile(0.65))\n",
    "\n",
    "# Calculate Bayesian Average\n",
    "movieProperties_df['bayesianAverage'] = (itemRatings * itemRatingsAverage + C * M) / (itemRatings + C)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(movieProperties_df['numRatings'], movieProperties_df['bayesianAverage'], alpha=0.5)\n",
    "plt.title('Bayesian Average vs. Number of ratings')\n",
    "plt.xlabel('Number of ratings')\n",
    "plt.ylabel('Bayesian Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show new movie properties dataframe, sorted by mean rating, where the number of ratings is greater than 2\n",
    "movieProperties_df[movieProperties_df['numRatings'] > 0].sort_values(by='bayesianAverage', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data to create user-item interaction matrices\n",
    "user_item_matrix = ratings_df.pivot(index='movieId', columns='userId', values='rating').fillna(0)\n",
    "Y = user_item_matrix\n",
    "\n",
    "# Display the user-item matrix\n",
    "print(\"User-Item Matrix:\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary indicator matrix for Y\n",
    "R = np.where(Y != 0, 1, 0)\n",
    "\n",
    "# Display the binary indicator matrix\n",
    "print(\"Binary Indicator:\\n\", R)\n",
    "print(\"\\nBinary Indicator shape:\", R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users))           : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users))   : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users))   : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_search(query, movies_df):\n",
    "    \"\"\"\n",
    "    Returns a list of movies that match the keyword or ID.\n",
    "\n",
    "    Args:\n",
    "      query (str or int): keyword to search for or movie ID\n",
    "      movies_df (DataFrame): DataFrame of movies\n",
    "\n",
    "    Returns:\n",
    "      results (DataFrame): DataFrame of movies that match the query\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(query, str):\n",
    "        # Search by keyword in title or genres\n",
    "        results = movies_df.loc[\n",
    "            movies_df['title'].str.contains(query, case=False, regex=True) |\n",
    "            movies_df['genres'].str.contains(query, case=False, regex=True)\n",
    "        ]\n",
    "    elif isinstance(query, int):\n",
    "        # Search by movie ID\n",
    "        results = movies_df.loc[movies_df['movieId'] == query]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid query type. Please provide a string (keyword) or an integer (movie ID).\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_search('lord of', movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare num_movies\n",
    "num_movies = movies_df.shape[0]\n",
    "\n",
    "# Initialize my_ratings based on the number of unique movies in movies_df\n",
    "my_ratings = np.zeros(num_movies)\n",
    "# Print my_ratings.shape\n",
    "print(\"my_ratings shape:\", my_ratings.shape)\n",
    "\n",
    "# Create a mapping between original movie IDs and their indices in my_ratings\n",
    "unique_movie_ids = movies_df[\"movieId\"].unique()\n",
    "movie_id_to_index = {movie_id: index for index, movie_id in enumerate(unique_movie_ids)}\n",
    "\n",
    "# Assign ratings at the correct positions using the mapping\n",
    "my_ratings[movie_id_to_index[2571]] = 4.5 # The Matrix (1999)\n",
    "my_ratings[movie_id_to_index[32]] = 4.0 # Twelve Monkeys (1995)\n",
    "my_ratings[movie_id_to_index[260]] = 4.0 # Star Wars: Episode IV - A New Hope (1977)\n",
    "my_ratings[movie_id_to_index[1196]] = 4.0 # Star Wars: Episode V - The Empire Strikes Back (1980)\n",
    "my_ratings[movie_id_to_index[296]] = 4.5 # Pulp Fiction (1994)\n",
    "my_ratings[movie_id_to_index[480]] = 3.5 # Jurassic Park (1993)\n",
    "my_ratings[movie_id_to_index[356]] = 4.5 # Forrest Gump (1994)\n",
    "my_ratings[movie_id_to_index[1]] = 4.0 # Toy Story (1995)\n",
    "my_ratings[movie_id_to_index[527]] = 4.0 # Schindler's List (1993)\n",
    "my_ratings[movie_id_to_index[4993]] = 5.0 # Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
    "my_ratings[movie_id_to_index[5952]] = 5.0 # Lord of the Rings: The Two Towers, The (2002)\n",
    "my_ratings[movie_id_to_index[7153]] = 5.0 # Lord of the Rings: The Return of the King, The (2003)\n",
    "my_ratings[movie_id_to_index[6539]] = 4.5 # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_ratings[movie_id_to_index[40815]] = 4.5 # Harry Potter and the Goblet of Fire (2005)\n",
    "my_ratings[movie_id_to_index[1704]] = 4.5 # Good Will Hunting (1997)\n",
    "\n",
    "print('\\n\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for   {movies_df.loc[i,\"title\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Y shape:\")\n",
    "# Print Y shape before adding new user ratings\n",
    "print(\"before:\", Y.shape)\n",
    "\n",
    "# Add the new user ratings to the Y matrix\n",
    "Y = np.c_[my_ratings, Y]\n",
    "# Print Y shape after adding new user ratings\n",
    "print(\"after:\", Y.shape)\n",
    "\n",
    "print(\"\\n\\nR shape:\")\n",
    "# Print R shape before adding new user ratings\n",
    "print(\"before:\", R.shape)\n",
    "\n",
    "# Update the binary indicator R matrix\n",
    "R = np.c_[np.where(my_ratings != 0, 1, 0), R]\n",
    "# Print R shape after adding new user ratings\n",
    "print(\"after:\", R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    \"\"\"\n",
    "    Normalizes Y so that each movie has a rating of 0 on average, and returns the mean rating in Ymean.\n",
    "    Args:\n",
    "      Y (ndarray (num_movies,num_users)): matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)): matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "    Returns:\n",
    "      Ynorm (ndarray (num_movies,num_users)): normalized Y with mean ratings subtracted\n",
    "      Ymean (ndarray (num_movies,1)): vector of mean ratings for each movie\n",
    "    \"\"\"\n",
    "    Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R)\n",
    "    return Ynorm, Ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize ratings\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "\n",
    "num_movies, num_users = Y.shape \n",
    "num_features = 100 # number of features to learn\n",
    "\n",
    "# Initialize parameters W, X, b\n",
    "tf.random.set_seed(1234) # set the random seed so this always produces the same results\n",
    "W = tf.Variable(tf.random.normal([num_users, num_features], dtype=tf.float64, name='W'))\n",
    "X = tf.Variable(tf.random.normal([num_movies, num_features], dtype=tf.float64, name='X'))\n",
    "b = tf.Variable(tf.random.normal([1, num_users], dtype=tf.float64, name='b'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, W, b, Y, R, lambda_, optimizer, iterations=200, print_every=20):\n",
    "    \"\"\"\n",
    "    Trains the collaborative filtering model using a custom training loop\n",
    "\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): Matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : Matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : Vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : Matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : Binary indicator matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): Regularization parameter\n",
    "      optimizer (tf.keras.optimizers): Optimizer to use for training\n",
    "      iterations (int): Number of iterations of gradient descent\n",
    "\n",
    "    Returns:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "    \"\"\"\n",
    "    # Initialize the cost history\n",
    "    cost_history = []\n",
    "\n",
    "    # Train using a custom training loop\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # Record the operations to compute the cost        \n",
    "        with tf.GradientTape() as tape:\n",
    "            J = cost_func(X, W, b, Y, R, lambda_)\n",
    "\n",
    "        # Compute the gradients using automatic differentiation    \n",
    "        grads = tape.gradient(J, [X, W, b])\n",
    "\n",
    "        # Update the parameters using the Adam optimizer\n",
    "        optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
    "\n",
    "        # Append the cost to the history\n",
    "        cost_history.append(J.numpy())\n",
    "\n",
    "        # Print the cost every 100 iterations\n",
    "        if i % print_every == 0:\n",
    "            print(f'Cost at iteration {i} is {J.numpy()}')\n",
    "    \n",
    "    return X, W, b, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using a custom training loop\n",
    "X, W, b, cost_history = train_model(X, W, b, Ynorm, R, lambda_=1, optimizer=optimizer, iterations=200, print_every=20)\n",
    "\n",
    "#Print the cost history\n",
    "print(\"\\nCost History:\", cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# Save my predictions to a dataframe, and sort the predictions from highest to lowest\n",
    "my_predictions_df = pd.DataFrame({'title': movieProperties_df['title'], 'number of ratings': movieProperties_df[\"numRatings\"], 'mean rating': movieProperties_df[\"meanRating\"], 'prediction': my_predictions.round(2), 'genres': movieProperties_df['genres']})\n",
    "my_predictions_df = my_predictions_df.sort_values(by='prediction', ascending=False)\n",
    "\n",
    "# Sort predictions and get the indices\n",
    "ix = np.argsort(my_predictions)[::-1]\n",
    "\n",
    "# Set a cap for the number of movies to print\n",
    "print_cap = 50\n",
    "# Set a cap for the release year\n",
    "release_year_cap = 1970\n",
    "# Set a cap for the number of ratings\n",
    "num_ratings_cap = 20\n",
    "\n",
    "# Initialize a counter for printed movies\n",
    "printed_count = 0\n",
    "\n",
    "for i in range(my_predictions.shape[0]):\n",
    "    j = ix[i]\n",
    "\n",
    "    try:\n",
    "        # Extract the release year using a regular expression\n",
    "        match = re.search(r'\\((\\d{4})\\)', movies_df.loc[j, \"title\"])\n",
    "\n",
    "        if match:\n",
    "            release_year = int(match.group(1))\n",
    "\n",
    "            # Check if the movie has over x ratings\n",
    "            if movieProperties_df.loc[j, \"numRatings\"] > num_ratings_cap and release_year > release_year_cap:\n",
    "                # Print the top 20 movies\n",
    "                print(f'numRatings: {movieProperties_df.loc[j, \"numRatings\"]}, Predicted {my_predictions[j]:0.2f} for    {movies_df.loc[j, \"title\"]}')\n",
    "                \n",
    "                # Increment the counter\n",
    "                printed_count += 1\n",
    "\n",
    "                # Check if 20 movies have been printed\n",
    "                if printed_count == print_cap:\n",
    "                    break\n",
    "    except (ValueError, IndexError):\n",
    "      # Handle errors in extracting the release year or accessing the list\n",
    "      print(f\"Error processing movie at index {j}. Skipping...\")\n",
    "      continue\n",
    "\n",
    "# Show original ratings and compare with predicted ratings\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for    {movies_df.iloc[i][\"title\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean rating of all movies in the pm matrix, including all users, and store it in a vector\n",
    "mean_rating_pm = np.mean(pm, axis=1)\n",
    "# Add predictions mean rating to the my_predictions_df, using the pm Matrix\n",
    "my_predictions_df.insert(4, 'predictionsMeanRating', mean_rating_pm[my_predictions_df.index])\n",
    "# Display the updated dataframe sorted by index\n",
    "print(\"My Predictions DataFrame:\")\n",
    "my_predictions_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a graph showing the mean rating of a movie vs My predictions rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(my_predictions_df['prediction'], my_predictions_df['mean rating'], alpha=0.5)\n",
    "plt.title('My predictions rating vs. Mean rating')\n",
    "plt.xlabel('My predictions rating')\n",
    "plt.ylabel('Mean rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a graph showing predictions mean ratings vs my predictions ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(my_predictions_df['prediction'], my_predictions_df['predictionsMeanRating'], alpha=0.5)\n",
    "plt.title('My predictions rating vs. Predictions mean rating')\n",
    "plt.xlabel('My predictions rating')\n",
    "plt.ylabel('Predictions mean rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a graph showing the mean rating of a movie vs predictions mean rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(my_predictions_df['mean rating'], my_predictions_df['predictionsMeanRating'], alpha=0.5)\n",
    "plt.title('Mean rating vs. Predictions mean rating')\n",
    "plt.xlabel('Mean rating')\n",
    "plt.ylabel('Predictions mean rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beysian_average(itemRatings, itemRatingsAverage, m, c):\n",
    "    \"\"\" \n",
    "    Returns the Bayesian average for the ratings\n",
    "    \n",
    "    Args:\n",
    "      itemRatings (ndarray): number of ratings for the movie\n",
    "      itemRatingsAverage (ndarray): average rating for the movie\n",
    "      m (float): parameter for Bayesian average, mean rating across all movies\n",
    "      c (float): parameter for Bayesian average, threshhold of the lower 25% of the number of ratings\n",
    "\n",
    "    Returns:\n",
    "        bayesianAverage (ndarray): Bayesian average for the ratings\n",
    "    \"\"\"\n",
    "    bayesianAverage = (itemRatings * itemRatingsAverage + c * m) / (itemRatings + c)\n",
    "    return bayesianAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a beysian average to predictions\n",
    "\n",
    "# Parameters\n",
    "c = movieProperties_df['numRatings'].quantile(0.65) # C is the threshhold of the lower 25% of the number of ratings, in this case 65% of the number of ratings, due to scarcity of ratings\n",
    "\n",
    "# Calculate BayesianPrediction\n",
    "#my_predictions_df['bayesianPrediction'] = (my_predictions_df['number of ratings'] * my_predictions_df['prediction'] + c * m) / (my_predictions_df['number of ratings'] + c)\n",
    "my_predictions_df['bayesianPrediction'] = beysian_average(my_predictions_df['number of ratings'], my_predictions_df['prediction'], my_predictions_df['prediction'].mean(), c)\n",
    "# Place BayesianPrediction column after the prediction column\n",
    "\n",
    "# Calculate bayesianPredictionMeanRating\n",
    "my_predictions_df['bayesianPredictionMeanRating'] = beysian_average(my_predictions_df['number of ratings'], my_predictions_df['predictionsMeanRating'], pm.mean(), c)\n",
    "#my_predictions_df['bayesianPredictionMeanRating'] = (my_predictions_df['number of ratings'] * my_predictions_df['predictionsMeanRating'] + c * m) / (my_predictions_df['number of ratings'] + c)\n",
    "\n",
    "# Calculate bayesianMeanRating\n",
    "#my_predictions_df['bayesianMeanRating'] = (my_predictions_df['number of ratings'] * my_predictions_df['mean rating'] + c * m) / (my_predictions_df['number of ratings'] + c)\n",
    "my_predictions_df['bayesianMeanRating'] = beysian_average(my_predictions_df['number of ratings'], my_predictions_df['mean rating'], ratings_df['rating'].mean(), c)\n",
    "\n",
    "# Order the columns\n",
    "my_predictions_df = my_predictions_df[['title', 'number of ratings', 'mean rating', 'bayesianMeanRating', 'prediction', 'bayesianPrediction', 'predictionsMeanRating', 'bayesianPredictionMeanRating', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display my_predictions_df, sorted by movie popularity (number of ratings)\n",
    "my_predictions_df.sort_values(by='bayesianPrediction', ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a graph showing the bayesian mean rating of a movie vs My bayesian predictions rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(my_predictions_df['bayesianPrediction'], my_predictions_df['bayesianMeanRating'], alpha=0.5)\n",
    "plt.title('My bayesian prediction rating vs. bayesian mean rating')\n",
    "plt.xlabel('My bayesian prediction rating')\n",
    "plt.ylabel('Bayesian mean rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_for_my_rated(predictions, targets, rated_indices):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Error for rated items between predictions and targets.\n",
    "\n",
    "    Args:\n",
    "      predictions (ndarray): Matrix of predicted ratings\n",
    "      targets (ndarray): Matrix of actual ratings\n",
    "      rated_indices (list): List of indices corresponding to rated items\n",
    "\n",
    "    Returns:\n",
    "      rmse (float): Root Mean Squared Error for rated items\n",
    "    \"\"\"\n",
    "    rated_predictions = predictions[rated_indices]\n",
    "    rated_targets = targets[rated_indices]\n",
    "\n",
    "    mse = np.mean((rated_predictions - rated_targets) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_for_all_users(predictions, targets, mask):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Error for all users between predictions and targets.\n",
    "\n",
    "    Args:\n",
    "      predictions (ndarray): Matrix of predicted ratings\n",
    "      targets (ndarray): Matrix of actual ratings\n",
    "      mask (ndarray): Binary indicator matrix (1 for rated items, 0 for unrated items)\n",
    "\n",
    "    Returns:\n",
    "      rmse (float): Root Mean Squared Error for all users\n",
    "    \"\"\"\n",
    "    # Apply the mask to focus on rated items\n",
    "    rated_predictions = predictions * mask\n",
    "    rated_targets = targets * mask\n",
    "\n",
    "    # Calculate RMSE only for rated items\n",
    "    mse = np.sum((rated_predictions - rated_targets) ** 2) / np.sum(mask)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae_for_my_rated(predictions, targets, rated_indices):\n",
    "    \"\"\"\n",
    "    Calculate Mean Absolute Error for rated items between predictions and targets.\n",
    "\n",
    "    Args:\n",
    "      predictions (ndarray): Matrix of predicted ratings\n",
    "      targets (ndarray): Matrix of actual ratings\n",
    "      rated_indices (list): List of indices corresponding to rated items\n",
    "\n",
    "    Returns:\n",
    "      mae (float): Mean Absolute Error for rated items\n",
    "    \"\"\"\n",
    "    rated_predictions = predictions[rated_indices]\n",
    "    rated_targets = targets[rated_indices]\n",
    "\n",
    "    mae = np.mean(np.abs(rated_predictions - rated_targets))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae_for_all_users(predictions, targets, mask):\n",
    "    \"\"\"\n",
    "    Calculate Mean Absolute Error for all users between predictions and targets.\n",
    "\n",
    "    Args:\n",
    "      predictions (ndarray): Matrix of predicted ratings\n",
    "      targets (ndarray): Matrix of actual ratings\n",
    "      mask (ndarray): Binary indicator matrix (1 for rated items, 0 for unrated items)\n",
    "\n",
    "    Returns:\n",
    "      mae (float): Mean Absolute Error for all users\n",
    "    \"\"\"\n",
    "    # Apply the mask to focus on rated items\n",
    "    rated_predictions = predictions * mask\n",
    "    rated_targets = targets * mask\n",
    "\n",
    "    # Calculate MAE only for rated items\n",
    "    mae = np.sum(np.abs(rated_predictions - rated_targets)) / np.sum(mask)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for RMSE and MAE all users calculations\n",
    "predictions = pm\n",
    "targets = Y\n",
    "mask = R\n",
    "\n",
    "# Get indices of rated items\n",
    "rated_indices = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "# Calculate RMSE for rated items\n",
    "rmse_for_rated = calculate_rmse_for_my_rated(my_predictions, my_ratings, rated_indices)\n",
    "print(f'RMSE for my rated items: {rmse_for_rated}')\n",
    "\n",
    "# Calculate RMSE for all users\n",
    "rmse_for_all_users = calculate_rmse_for_all_users(predictions, targets, mask)\n",
    "print(f'\\nRMSE for all users: {rmse_for_all_users}')\n",
    "\n",
    "# Calculate MAE for rated items\n",
    "mae_for_rated = calculate_mae_for_my_rated(my_predictions, my_ratings, rated_indices)\n",
    "print(f'\\nMAE for my rated items: {mae_for_rated}')\n",
    "\n",
    "# Calculate MAE for all users\n",
    "mae_for_all_users = calculate_mae_for_all_users(predictions, targets, mask)\n",
    "print(f'\\nMAE for all users: {mae_for_all_users}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_search('Adventure', my_predictions_df).sort_values(by='bayesianPrediction', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search sort function to sort predictions by genre, release year, or popularity\n",
    "def search_sort(df, genre=None, release_year=None, num_ratings=None):\n",
    "    \"\"\"\n",
    "    Returns a list of movies that match the genre, release year, or number of ratings.\n",
    "\n",
    "    Args:\n",
    "      df (DataFrame): DataFrame of movies\n",
    "      genre (str): genre to search for\n",
    "      release_year (int): minimum release year to search for\n",
    "      num_ratings (int): number of ratings to search for\n",
    "\n",
    "    Returns:\n",
    "      results (DataFrame): DataFrame of movies that match the query\n",
    "    \"\"\"\n",
    "    conditions = []\n",
    "\n",
    "    if genre:\n",
    "        conditions.append(df['genres'].str.contains(genre, case=False, regex=True))\n",
    "    if release_year:\n",
    "        # Extract release year from the title and compare with the provided release_year\n",
    "        conditions.append(df['title'].str.extract(r'\\((\\d{4})\\)', expand=False).astype(float) >= release_year)\n",
    "    if num_ratings:\n",
    "        conditions.append(df['number of ratings'] > num_ratings)\n",
    "\n",
    "    if conditions:\n",
    "        combined_condition = pd.DataFrame(conditions).all()\n",
    "        results = df.loc[combined_condition]\n",
    "        return results.sort_values(by='bayesianPrediction', ascending=False)\n",
    "    else:\n",
    "        raise ValueError(\"At least one search term is required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sort(my_predictions_df, genre='action', release_year=2017).head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
